{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92ffac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T17:28:29.095756Z",
     "iopub.status.busy": "2022-03-22T17:28:29.011678Z",
     "iopub.status.idle": "2022-03-22T17:28:42.470290Z",
     "shell.execute_reply": "2022-03-22T17:28:42.469688Z",
     "shell.execute_reply.started": "2022-03-22T17:23:46.061745Z"
    },
    "papermill": {
     "duration": 13.496335,
     "end_time": "2022-03-22T17:28:42.470456",
     "exception": false,
     "start_time": "2022-03-22T17:28:28.974121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q timm pytorch-metric-learning\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from pytorch_metric_learning import losses\n",
    "from torch.cuda import amp\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.autograd import Variable\n",
    "from collections import defaultdict, OrderedDict\n",
    "import copy\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "from PIL import Image, ImageOps, ImageEnhance, ImageChops\n",
    "import PIL\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "_PIL_VER = tuple([int(x) for x in PIL.__version__.split('.')[:2]])\n",
    "\n",
    "_FILL = (128, 128, 128)\n",
    "\n",
    "_LEVEL_DENOM = 10.  # denominator for conversion from 'Mx' magnitude scale to fractional aug level for op arguments\n",
    "\n",
    "_HPARAMS_DEFAULT = dict(\n",
    "    translate_const=250,\n",
    "    img_mean=_FILL,\n",
    ")\n",
    "\n",
    "_RANDOM_INTERPOLATION = (Image.BILINEAR, Image.BICUBIC)\n",
    "\n",
    "\n",
    "def _interpolation(kwargs):\n",
    "    interpolation = kwargs.pop('resample', Image.BILINEAR)\n",
    "    if isinstance(interpolation, (list, tuple)):\n",
    "        return random.choice(interpolation)\n",
    "    else:\n",
    "        return interpolation\n",
    "\n",
    "\n",
    "def _check_args_tf(kwargs):\n",
    "    if 'fillcolor' in kwargs and _PIL_VER < (5, 0):\n",
    "        kwargs.pop('fillcolor')\n",
    "    kwargs['resample'] = _interpolation(kwargs)\n",
    "\n",
    "\n",
    "def shear_x(img, factor, **kwargs):\n",
    "    _check_args_tf(kwargs)\n",
    "    return img.transform(img.size, Image.AFFINE, (1, factor, 0, 0, 1, 0), **kwargs)\n",
    "\n",
    "\n",
    "def shear_y(img, factor, **kwargs):\n",
    "    _check_args_tf(kwargs)\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, 0, factor, 1, 0), **kwargs)\n",
    "\n",
    "\n",
    "def translate_x_rel(img, pct, **kwargs):\n",
    "    pixels = pct * img.size[0]\n",
    "    _check_args_tf(kwargs)\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, pixels, 0, 1, 0), **kwargs)\n",
    "\n",
    "\n",
    "def translate_y_rel(img, pct, **kwargs):\n",
    "    pixels = pct * img.size[1]\n",
    "    _check_args_tf(kwargs)\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, pixels), **kwargs)\n",
    "\n",
    "\n",
    "def translate_x_abs(img, pixels, **kwargs):\n",
    "    _check_args_tf(kwargs)\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, pixels, 0, 1, 0), **kwargs)\n",
    "\n",
    "\n",
    "def translate_y_abs(img, pixels, **kwargs):\n",
    "    _check_args_tf(kwargs)\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, pixels), **kwargs)\n",
    "\n",
    "\n",
    "def rotate(img, degrees, **kwargs):\n",
    "    _check_args_tf(kwargs)\n",
    "    if _PIL_VER >= (5, 2):\n",
    "        return img.rotate(degrees, **kwargs)\n",
    "    elif _PIL_VER >= (5, 0):\n",
    "        w, h = img.size\n",
    "        post_trans = (0, 0)\n",
    "        rotn_center = (w / 2.0, h / 2.0)\n",
    "        angle = -math.radians(degrees)\n",
    "        matrix = [\n",
    "            round(math.cos(angle), 15),\n",
    "            round(math.sin(angle), 15),\n",
    "            0.0,\n",
    "            round(-math.sin(angle), 15),\n",
    "            round(math.cos(angle), 15),\n",
    "            0.0,\n",
    "        ]\n",
    "\n",
    "        def transform(x, y, matrix):\n",
    "            (a, b, c, d, e, f) = matrix\n",
    "            return a * x + b * y + c, d * x + e * y + f\n",
    "\n",
    "        matrix[2], matrix[5] = transform(\n",
    "            -rotn_center[0] - post_trans[0], -rotn_center[1] - post_trans[1], matrix\n",
    "        )\n",
    "        matrix[2] += rotn_center[0]\n",
    "        matrix[5] += rotn_center[1]\n",
    "        return img.transform(img.size, Image.AFFINE, matrix, **kwargs)\n",
    "    else:\n",
    "        return img.rotate(degrees, resample=kwargs['resample'])\n",
    "\n",
    "\n",
    "def auto_contrast(img, **__):\n",
    "    return ImageOps.autocontrast(img)\n",
    "\n",
    "\n",
    "def invert(img, **__):\n",
    "    return ImageOps.invert(img)\n",
    "\n",
    "\n",
    "def equalize(img, **__):\n",
    "    return ImageOps.equalize(img)\n",
    "\n",
    "\n",
    "def solarize(img, thresh, **__):\n",
    "    return ImageOps.solarize(img, thresh)\n",
    "\n",
    "\n",
    "def solarize_add(img, add, thresh=128, **__):\n",
    "    lut = []\n",
    "    for i in range(256):\n",
    "        if i < thresh:\n",
    "            lut.append(min(255, i + add))\n",
    "        else:\n",
    "            lut.append(i)\n",
    "    if img.mode in (\"L\", \"RGB\"):\n",
    "        if img.mode == \"RGB\" and len(lut) == 256:\n",
    "            lut = lut + lut + lut\n",
    "        return img.point(lut)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "\n",
    "def posterize(img, bits_to_keep, **__):\n",
    "    if bits_to_keep >= 8:\n",
    "        return img\n",
    "    return ImageOps.posterize(img, bits_to_keep)\n",
    "\n",
    "\n",
    "def contrast(img, factor, **__):\n",
    "    return ImageEnhance.Contrast(img).enhance(factor)\n",
    "\n",
    "\n",
    "def color(img, factor, **__):\n",
    "    return ImageEnhance.Color(img).enhance(factor)\n",
    "\n",
    "\n",
    "def brightness(img, factor, **__):\n",
    "    return ImageEnhance.Brightness(img).enhance(factor)\n",
    "\n",
    "\n",
    "def sharpness(img, factor, **__):\n",
    "    return ImageEnhance.Sharpness(img).enhance(factor)\n",
    "\n",
    "\n",
    "def _randomly_negate(v):\n",
    "    \"\"\"With 50% prob, negate the value\"\"\"\n",
    "    return -v if random.random() > 0.5 else v\n",
    "\n",
    "\n",
    "def _rotate_level_to_arg(level, _hparams):\n",
    "    # range [-30, 30]\n",
    "    level = (level / _LEVEL_DENOM) * 30.\n",
    "    level = _randomly_negate(level)\n",
    "    return level,\n",
    "\n",
    "\n",
    "def _enhance_level_to_arg(level, _hparams):\n",
    "    # range [0.1, 1.9]\n",
    "    return (level / _LEVEL_DENOM) * 1.8 + 0.1,\n",
    "\n",
    "\n",
    "def _enhance_increasing_level_to_arg(level, _hparams):\n",
    "    # the 'no change' level is 1.0, moving away from that towards 0. or 2.0 increases the enhancement blend\n",
    "    # range [0.1, 1.9] if level <= _LEVEL_DENOM\n",
    "    level = (level / _LEVEL_DENOM) * .9\n",
    "    level = max(0.1, 1.0 + _randomly_negate(level))  # keep it >= 0.1\n",
    "    return level,\n",
    "\n",
    "\n",
    "def _shear_level_to_arg(level, _hparams):\n",
    "    # range [-0.3, 0.3]\n",
    "    level = (level / _LEVEL_DENOM) * 0.3\n",
    "    level = _randomly_negate(level)\n",
    "    return level,\n",
    "\n",
    "\n",
    "def _translate_abs_level_to_arg(level, hparams):\n",
    "    translate_const = hparams['translate_const']\n",
    "    level = (level / _LEVEL_DENOM) * float(translate_const)\n",
    "    level = _randomly_negate(level)\n",
    "    return level,\n",
    "\n",
    "\n",
    "def _translate_rel_level_to_arg(level, hparams):\n",
    "    # default range [-0.45, 0.45]\n",
    "    translate_pct = hparams.get('translate_pct', 0.45)\n",
    "    level = (level / _LEVEL_DENOM) * translate_pct\n",
    "    level = _randomly_negate(level)\n",
    "    return level,\n",
    "\n",
    "\n",
    "def _posterize_level_to_arg(level, _hparams):\n",
    "    # As per Tensorflow TPU EfficientNet impl\n",
    "    # range [0, 4], 'keep 0 up to 4 MSB of original image'\n",
    "    # intensity/severity of augmentation decreases with level\n",
    "    return int((level / _LEVEL_DENOM) * 4),\n",
    "\n",
    "\n",
    "def _posterize_increasing_level_to_arg(level, hparams):\n",
    "    # As per Tensorflow models research and UDA impl\n",
    "    # range [4, 0], 'keep 4 down to 0 MSB of original image',\n",
    "    # intensity/severity of augmentation increases with level\n",
    "    return 4 - _posterize_level_to_arg(level, hparams)[0],\n",
    "\n",
    "\n",
    "def _posterize_original_level_to_arg(level, _hparams):\n",
    "    # As per original AutoAugment paper description\n",
    "    # range [4, 8], 'keep 4 up to 8 MSB of image'\n",
    "    # intensity/severity of augmentation decreases with level\n",
    "    return int((level / _LEVEL_DENOM) * 4) + 4,\n",
    "\n",
    "\n",
    "def _solarize_level_to_arg(level, _hparams):\n",
    "    # range [0, 256]\n",
    "    # intensity/severity of augmentation decreases with level\n",
    "    return int((level / _LEVEL_DENOM) * 256),\n",
    "\n",
    "\n",
    "def _solarize_increasing_level_to_arg(level, _hparams):\n",
    "    # range [0, 256]\n",
    "    # intensity/severity of augmentation increases with level\n",
    "    return 256 - _solarize_level_to_arg(level, _hparams)[0],\n",
    "\n",
    "\n",
    "def _solarize_add_level_to_arg(level, _hparams):\n",
    "    # range [0, 110]\n",
    "    return int((level / _LEVEL_DENOM) * 110),\n",
    "\n",
    "\n",
    "LEVEL_TO_ARG = {\n",
    "    'AutoContrast': None,\n",
    "    'Equalize': None,\n",
    "    'Invert': None,\n",
    "    'Rotate': _rotate_level_to_arg,\n",
    "    # There are several variations of the posterize level scaling in various Tensorflow/Google repositories/papers\n",
    "    'Posterize': _posterize_level_to_arg,\n",
    "    'PosterizeIncreasing': _posterize_increasing_level_to_arg,\n",
    "    'PosterizeOriginal': _posterize_original_level_to_arg,\n",
    "    'Solarize': _solarize_level_to_arg,\n",
    "    'SolarizeIncreasing': _solarize_increasing_level_to_arg,\n",
    "    'SolarizeAdd': _solarize_add_level_to_arg,\n",
    "    'Color': _enhance_level_to_arg,\n",
    "    'ColorIncreasing': _enhance_increasing_level_to_arg,\n",
    "    'Contrast': _enhance_level_to_arg,\n",
    "    'ContrastIncreasing': _enhance_increasing_level_to_arg,\n",
    "    'Brightness': _enhance_level_to_arg,\n",
    "    'BrightnessIncreasing': _enhance_increasing_level_to_arg,\n",
    "    'Sharpness': _enhance_level_to_arg,\n",
    "    'SharpnessIncreasing': _enhance_increasing_level_to_arg,\n",
    "    'ShearX': _shear_level_to_arg,\n",
    "    'ShearY': _shear_level_to_arg,\n",
    "    'TranslateX': _translate_abs_level_to_arg,\n",
    "    'TranslateY': _translate_abs_level_to_arg,\n",
    "    'TranslateXRel': _translate_rel_level_to_arg,\n",
    "    'TranslateYRel': _translate_rel_level_to_arg,\n",
    "}\n",
    "\n",
    "\n",
    "NAME_TO_OP = {\n",
    "    'AutoContrast': auto_contrast,\n",
    "    'Equalize': equalize,\n",
    "    'Invert': invert,\n",
    "    'Rotate': rotate,\n",
    "    'Posterize': posterize,\n",
    "    'PosterizeIncreasing': posterize,\n",
    "    'PosterizeOriginal': posterize,\n",
    "    'Solarize': solarize,\n",
    "    'SolarizeIncreasing': solarize,\n",
    "    'SolarizeAdd': solarize_add,\n",
    "    'Color': color,\n",
    "    'ColorIncreasing': color,\n",
    "    'Contrast': contrast,\n",
    "    'ContrastIncreasing': contrast,\n",
    "    'Brightness': brightness,\n",
    "    'BrightnessIncreasing': brightness,\n",
    "    'Sharpness': sharpness,\n",
    "    'SharpnessIncreasing': sharpness,\n",
    "    'ShearX': shear_x,\n",
    "    'ShearY': shear_y,\n",
    "    'TranslateX': translate_x_abs,\n",
    "    'TranslateY': translate_y_abs,\n",
    "    'TranslateXRel': translate_x_rel,\n",
    "    'TranslateYRel': translate_y_rel,\n",
    "}\n",
    "\n",
    "\n",
    "class AugmentOp:\n",
    "\n",
    "    def __init__(self, name, prob=0.5, magnitude=10, hparams=None):\n",
    "        hparams = hparams or _HPARAMS_DEFAULT\n",
    "        self.name = name\n",
    "        self.aug_fn = NAME_TO_OP[name]\n",
    "        self.level_fn = LEVEL_TO_ARG[name]\n",
    "        self.prob = prob\n",
    "        self.magnitude = magnitude\n",
    "        self.hparams = hparams.copy()\n",
    "        self.kwargs = dict(\n",
    "            fillcolor=hparams['img_mean'] if 'img_mean' in hparams else _FILL,\n",
    "            resample=hparams['interpolation'] if 'interpolation' in hparams else _RANDOM_INTERPOLATION,\n",
    "        )\n",
    "\n",
    "        # If magnitude_std is > 0, we introduce some randomness\n",
    "        # in the usually fixed policy and sample magnitude from a normal distribution\n",
    "        # with mean `magnitude` and std-dev of `magnitude_std`.\n",
    "        # NOTE This is my own hack, being tested, not in papers or reference impls.\n",
    "        # If magnitude_std is inf, we sample magnitude from a uniform distribution\n",
    "        self.magnitude_std = self.hparams.get('magnitude_std', 0)\n",
    "        self.magnitude_max = self.hparams.get('magnitude_max', None)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.prob < 1.0 and random.random() > self.prob:\n",
    "            return img\n",
    "        magnitude = self.magnitude\n",
    "        if self.magnitude_std > 0:\n",
    "            # magnitude randomization enabled\n",
    "            if self.magnitude_std == float('inf'):\n",
    "                magnitude = random.uniform(0, magnitude)\n",
    "            elif self.magnitude_std > 0:\n",
    "                magnitude = random.gauss(magnitude, self.magnitude_std)\n",
    "        # default upper_bound for the timm RA impl is _LEVEL_DENOM (10)\n",
    "        # setting magnitude_max overrides this to allow M > 10 (behaviour closer to Google TF RA impl)\n",
    "        upper_bound = self.magnitude_max or _LEVEL_DENOM\n",
    "        magnitude = max(0., min(magnitude, upper_bound))\n",
    "        level_args = self.level_fn(magnitude, self.hparams) if self.level_fn is not None else tuple()\n",
    "        return self.aug_fn(img, *level_args, **self.kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        fs = self.__class__.__name__ + f'(name={self.name}, p={self.prob}'\n",
    "        fs += f', m={self.magnitude}, mstd={self.magnitude_std}'\n",
    "        if self.magnitude_max is not None:\n",
    "            fs += f', mmax={self.magnitude_max}'\n",
    "        fs += ')'\n",
    "        return fs\n",
    "\n",
    "\n",
    "def auto_augment_policy_v0(hparams):\n",
    "    # ImageNet v0 policy from TPU EfficientNet impl, cannot find a paper reference.\n",
    "    policy = [\n",
    "        [('Equalize', 0.8, 1), ('ShearY', 0.8, 4)],\n",
    "        [('Color', 0.4, 9), ('Equalize', 0.6, 3)],\n",
    "        [('Color', 0.4, 1), ('Rotate', 0.6, 8)],\n",
    "        [('Solarize', 0.8, 3), ('Equalize', 0.4, 7)],\n",
    "        [('Solarize', 0.4, 2), ('Solarize', 0.6, 2)],\n",
    "        [('Color', 0.2, 0), ('Equalize', 0.8, 8)],\n",
    "        [('Equalize', 0.4, 8), ('SolarizeAdd', 0.8, 3)],\n",
    "        [('ShearX', 0.2, 9), ('Rotate', 0.6, 8)],\n",
    "        [('Color', 0.6, 1), ('Equalize', 1.0, 2)],\n",
    "        [('Invert', 0.4, 9), ('Rotate', 0.6, 0)],\n",
    "        [('Equalize', 1.0, 9), ('ShearY', 0.6, 3)],\n",
    "        [('Color', 0.4, 7), ('Equalize', 0.6, 0)],\n",
    "        [('Posterize', 0.4, 6), ('AutoContrast', 0.4, 7)],\n",
    "        [('Solarize', 0.6, 8), ('Color', 0.6, 9)],\n",
    "        [('Solarize', 0.2, 4), ('Rotate', 0.8, 9)],\n",
    "        [('Rotate', 1.0, 7), ('TranslateYRel', 0.8, 9)],\n",
    "        [('ShearX', 0.0, 0), ('Solarize', 0.8, 4)],\n",
    "        [('ShearY', 0.8, 0), ('Color', 0.6, 4)],\n",
    "        [('Color', 1.0, 0), ('Rotate', 0.6, 2)],\n",
    "        [('Equalize', 0.8, 4), ('Equalize', 0.0, 8)],\n",
    "        [('Equalize', 1.0, 4), ('AutoContrast', 0.6, 2)],\n",
    "        [('ShearY', 0.4, 7), ('SolarizeAdd', 0.6, 7)],\n",
    "        [('Posterize', 0.8, 2), ('Solarize', 0.6, 10)],  # This results in black image with Tpu posterize\n",
    "        [('Solarize', 0.6, 8), ('Equalize', 0.6, 1)],\n",
    "        [('Color', 0.8, 6), ('Rotate', 0.4, 5)],\n",
    "    ]\n",
    "    pc = [[AugmentOp(*a, hparams=hparams) for a in sp] for sp in policy]\n",
    "    return pc\n",
    "\n",
    "\n",
    "def auto_augment_policy_v0r(hparams):\n",
    "    # ImageNet v0 policy from TPU EfficientNet impl, with variation of Posterize used\n",
    "    # in Google research implementation (number of bits discarded increases with magnitude)\n",
    "    policy = [\n",
    "        [('Equalize', 0.8, 1), ('ShearY', 0.8, 4)],\n",
    "        [('Color', 0.4, 9), ('Equalize', 0.6, 3)],\n",
    "        [('Color', 0.4, 1), ('Rotate', 0.6, 8)],\n",
    "        [('Solarize', 0.8, 3), ('Equalize', 0.4, 7)],\n",
    "        [('Solarize', 0.4, 2), ('Solarize', 0.6, 2)],\n",
    "        [('Color', 0.2, 0), ('Equalize', 0.8, 8)],\n",
    "        [('Equalize', 0.4, 8), ('SolarizeAdd', 0.8, 3)],\n",
    "        [('ShearX', 0.2, 9), ('Rotate', 0.6, 8)],\n",
    "        [('Color', 0.6, 1), ('Equalize', 1.0, 2)],\n",
    "        [('Invert', 0.4, 9), ('Rotate', 0.6, 0)],\n",
    "        [('Equalize', 1.0, 9), ('ShearY', 0.6, 3)],\n",
    "        [('Color', 0.4, 7), ('Equalize', 0.6, 0)],\n",
    "        [('PosterizeIncreasing', 0.4, 6), ('AutoContrast', 0.4, 7)],\n",
    "        [('Solarize', 0.6, 8), ('Color', 0.6, 9)],\n",
    "        [('Solarize', 0.2, 4), ('Rotate', 0.8, 9)],\n",
    "        [('Rotate', 1.0, 7), ('TranslateYRel', 0.8, 9)],\n",
    "        [('ShearX', 0.0, 0), ('Solarize', 0.8, 4)],\n",
    "        [('ShearY', 0.8, 0), ('Color', 0.6, 4)],\n",
    "        [('Color', 1.0, 0), ('Rotate', 0.6, 2)],\n",
    "        [('Equalize', 0.8, 4), ('Equalize', 0.0, 8)],\n",
    "        [('Equalize', 1.0, 4), ('AutoContrast', 0.6, 2)],\n",
    "        [('ShearY', 0.4, 7), ('SolarizeAdd', 0.6, 7)],\n",
    "        [('PosterizeIncreasing', 0.8, 2), ('Solarize', 0.6, 10)],\n",
    "        [('Solarize', 0.6, 8), ('Equalize', 0.6, 1)],\n",
    "        [('Color', 0.8, 6), ('Rotate', 0.4, 5)],\n",
    "    ]\n",
    "    pc = [[AugmentOp(*a, hparams=hparams) for a in sp] for sp in policy]\n",
    "    return pc\n",
    "\n",
    "\n",
    "def auto_augment_policy_original(hparams):\n",
    "    # ImageNet policy from https://arxiv.org/abs/1805.09501\n",
    "    policy = [\n",
    "        [('PosterizeOriginal', 0.4, 8), ('Rotate', 0.6, 9)],\n",
    "        [('Solarize', 0.6, 5), ('AutoContrast', 0.6, 5)],\n",
    "        [('Equalize', 0.8, 8), ('Equalize', 0.6, 3)],\n",
    "        [('PosterizeOriginal', 0.6, 7), ('PosterizeOriginal', 0.6, 6)],\n",
    "        [('Equalize', 0.4, 7), ('Solarize', 0.2, 4)],\n",
    "        [('Equalize', 0.4, 4), ('Rotate', 0.8, 8)],\n",
    "        [('Solarize', 0.6, 3), ('Equalize', 0.6, 7)],\n",
    "        [('PosterizeOriginal', 0.8, 5), ('Equalize', 1.0, 2)],\n",
    "        [('Rotate', 0.2, 3), ('Solarize', 0.6, 8)],\n",
    "        [('Equalize', 0.6, 8), ('PosterizeOriginal', 0.4, 6)],\n",
    "        [('Rotate', 0.8, 8), ('Color', 0.4, 0)],\n",
    "        [('Rotate', 0.4, 9), ('Equalize', 0.6, 2)],\n",
    "        [('Equalize', 0.0, 7), ('Equalize', 0.8, 8)],\n",
    "        [('Invert', 0.6, 4), ('Equalize', 1.0, 8)],\n",
    "        [('Color', 0.6, 4), ('Contrast', 1.0, 8)],\n",
    "        [('Rotate', 0.8, 8), ('Color', 1.0, 2)],\n",
    "        [('Color', 0.8, 8), ('Solarize', 0.8, 7)],\n",
    "        [('Sharpness', 0.4, 7), ('Invert', 0.6, 8)],\n",
    "        [('ShearX', 0.6, 5), ('Equalize', 1.0, 9)],\n",
    "        [('Color', 0.4, 0), ('Equalize', 0.6, 3)],\n",
    "        [('Equalize', 0.4, 7), ('Solarize', 0.2, 4)],\n",
    "        [('Solarize', 0.6, 5), ('AutoContrast', 0.6, 5)],\n",
    "        [('Invert', 0.6, 4), ('Equalize', 1.0, 8)],\n",
    "        [('Color', 0.6, 4), ('Contrast', 1.0, 8)],\n",
    "        [('Equalize', 0.8, 8), ('Equalize', 0.6, 3)],\n",
    "    ]\n",
    "    pc = [[AugmentOp(*a, hparams=hparams) for a in sp] for sp in policy]\n",
    "    return pc\n",
    "\n",
    "\n",
    "def auto_augment_policy_originalr(hparams):\n",
    "    # ImageNet policy from https://arxiv.org/abs/1805.09501 with research posterize variation\n",
    "    policy = [\n",
    "        [('PosterizeIncreasing', 0.4, 8), ('Rotate', 0.6, 9)],\n",
    "        [('Solarize', 0.6, 5), ('AutoContrast', 0.6, 5)],\n",
    "        [('Equalize', 0.8, 8), ('Equalize', 0.6, 3)],\n",
    "        [('PosterizeIncreasing', 0.6, 7), ('PosterizeIncreasing', 0.6, 6)],\n",
    "        [('Equalize', 0.4, 7), ('Solarize', 0.2, 4)],\n",
    "        [('Equalize', 0.4, 4), ('Rotate', 0.8, 8)],\n",
    "        [('Solarize', 0.6, 3), ('Equalize', 0.6, 7)],\n",
    "        [('PosterizeIncreasing', 0.8, 5), ('Equalize', 1.0, 2)],\n",
    "        [('Rotate', 0.2, 3), ('Solarize', 0.6, 8)],\n",
    "        [('Equalize', 0.6, 8), ('PosterizeIncreasing', 0.4, 6)],\n",
    "        [('Rotate', 0.8, 8), ('Color', 0.4, 0)],\n",
    "        [('Rotate', 0.4, 9), ('Equalize', 0.6, 2)],\n",
    "        [('Equalize', 0.0, 7), ('Equalize', 0.8, 8)],\n",
    "        [('Invert', 0.6, 4), ('Equalize', 1.0, 8)],\n",
    "        [('Color', 0.6, 4), ('Contrast', 1.0, 8)],\n",
    "        [('Rotate', 0.8, 8), ('Color', 1.0, 2)],\n",
    "        [('Color', 0.8, 8), ('Solarize', 0.8, 7)],\n",
    "        [('Sharpness', 0.4, 7), ('Invert', 0.6, 8)],\n",
    "        [('ShearX', 0.6, 5), ('Equalize', 1.0, 9)],\n",
    "        [('Color', 0.4, 0), ('Equalize', 0.6, 3)],\n",
    "        [('Equalize', 0.4, 7), ('Solarize', 0.2, 4)],\n",
    "        [('Solarize', 0.6, 5), ('AutoContrast', 0.6, 5)],\n",
    "        [('Invert', 0.6, 4), ('Equalize', 1.0, 8)],\n",
    "        [('Color', 0.6, 4), ('Contrast', 1.0, 8)],\n",
    "        [('Equalize', 0.8, 8), ('Equalize', 0.6, 3)],\n",
    "    ]\n",
    "    pc = [[AugmentOp(*a, hparams=hparams) for a in sp] for sp in policy]\n",
    "    return pc\n",
    "\n",
    "\n",
    "def auto_augment_policy(name='v0', hparams=None):\n",
    "    hparams = hparams or _HPARAMS_DEFAULT\n",
    "    if name == 'original':\n",
    "        return auto_augment_policy_original(hparams)\n",
    "    elif name == 'originalr':\n",
    "        return auto_augment_policy_originalr(hparams)\n",
    "    elif name == 'v0':\n",
    "        return auto_augment_policy_v0(hparams)\n",
    "    elif name == 'v0r':\n",
    "        return auto_augment_policy_v0r(hparams)\n",
    "    else:\n",
    "        assert False, 'Unknown AA policy (%s)' % name\n",
    "\n",
    "\n",
    "class AutoAugment:\n",
    "\n",
    "    def __init__(self, policy):\n",
    "        self.policy = policy\n",
    "\n",
    "    def __call__(self, img):\n",
    "        sub_policy = random.choice(self.policy)\n",
    "        for op in sub_policy:\n",
    "            img = op(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        fs = self.__class__.__name__ + f'(policy='\n",
    "        for p in self.policy:\n",
    "            fs += '\\n\\t['\n",
    "            fs += ', '.join([str(op) for op in p])\n",
    "            fs += ']'\n",
    "        fs += ')'\n",
    "        return fs\n",
    "\n",
    "\n",
    "def auto_augment_transform(config_str, hparams):\n",
    "    \"\"\"\n",
    "    Create a AutoAugment transform\n",
    "    :param config_str: String defining configuration of auto augmentation. Consists of multiple sections separated by\n",
    "    dashes ('-'). The first section defines the AutoAugment policy (one of 'v0', 'v0r', 'original', 'originalr').\n",
    "    The remaining sections, not order sepecific determine\n",
    "        'mstd' -  float std deviation of magnitude noise applied\n",
    "    Ex 'original-mstd0.5' results in AutoAugment with original policy, magnitude_std 0.5\n",
    "    :param hparams: Other hparams (kwargs) for the AutoAugmentation scheme\n",
    "    :return: A PyTorch compatible Transform\n",
    "    \"\"\"\n",
    "    config = config_str.split('-')\n",
    "    policy_name = config[0]\n",
    "    config = config[1:]\n",
    "    for c in config:\n",
    "        cs = re.split(r'(\\d.*)', c)\n",
    "        if len(cs) < 2:\n",
    "            continue\n",
    "        key, val = cs[:2]\n",
    "        if key == 'mstd':\n",
    "            # noise param injected via hparams for now\n",
    "            hparams.setdefault('magnitude_std', float(val))\n",
    "        else:\n",
    "            assert False, 'Unknown AutoAugment config section'\n",
    "    aa_policy = auto_augment_policy(policy_name, hparams=hparams)\n",
    "    return AutoAugment(aa_policy)\n",
    "\n",
    "\n",
    "_RAND_TRANSFORMS = [\n",
    "    'AutoContrast',\n",
    "    'Equalize',\n",
    "    'Invert',\n",
    "    'Rotate',\n",
    "    'Posterize',\n",
    "    'Solarize',\n",
    "    'SolarizeAdd',\n",
    "    'Color',\n",
    "    'Contrast',\n",
    "    'Brightness',\n",
    "    'Sharpness',\n",
    "    'ShearX',\n",
    "    'ShearY',\n",
    "    'TranslateXRel',\n",
    "    'TranslateYRel',\n",
    "    #'Cutout'  # NOTE I've implement this as random erasing separately\n",
    "]\n",
    "\n",
    "\n",
    "_RAND_INCREASING_TRANSFORMS = [\n",
    "    'AutoContrast',\n",
    "    'Equalize',\n",
    "    'Invert',\n",
    "    'Rotate',\n",
    "    'PosterizeIncreasing',\n",
    "    'SolarizeIncreasing',\n",
    "    'SolarizeAdd',\n",
    "    'ColorIncreasing',\n",
    "    'ContrastIncreasing',\n",
    "    'BrightnessIncreasing',\n",
    "    'SharpnessIncreasing',\n",
    "    'ShearX',\n",
    "    'ShearY',\n",
    "    'TranslateXRel',\n",
    "    'TranslateYRel',\n",
    "    #'Cutout'  # NOTE I've implement this as random erasing separately\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# These experimental weights are based loosely on the relative improvements mentioned in paper.\n",
    "# They may not result in increased performance, but could likely be tuned to so.\n",
    "_RAND_CHOICE_WEIGHTS_0 = {\n",
    "    'Rotate': 0.3,\n",
    "    'ShearX': 0.2,\n",
    "    'ShearY': 0.2,\n",
    "    'TranslateXRel': 0.1,\n",
    "    'TranslateYRel': 0.1,\n",
    "    'Color': .025,\n",
    "    'Sharpness': 0.025,\n",
    "    'AutoContrast': 0.025,\n",
    "    'Solarize': .005,\n",
    "    'SolarizeAdd': .005,\n",
    "    'Contrast': .005,\n",
    "    'Brightness': .005,\n",
    "    'Equalize': .005,\n",
    "    'Posterize': 0,\n",
    "    'Invert': 0,\n",
    "}\n",
    "\n",
    "\n",
    "def _select_rand_weights(weight_idx=0, transforms=None):\n",
    "    transforms = transforms or _RAND_TRANSFORMS\n",
    "    assert weight_idx == 0  # only one set of weights currently\n",
    "    rand_weights = _RAND_CHOICE_WEIGHTS_0\n",
    "    probs = [rand_weights[k] for k in transforms]\n",
    "    probs /= np.sum(probs)\n",
    "    return probs\n",
    "\n",
    "\n",
    "def rand_augment_ops(magnitude=10, hparams=None, transforms=None):\n",
    "    hparams = hparams or _HPARAMS_DEFAULT\n",
    "    transforms = transforms or _RAND_TRANSFORMS\n",
    "    return [AugmentOp(\n",
    "        name, prob=0.5, magnitude=magnitude, hparams=hparams) for name in transforms]\n",
    "\n",
    "\n",
    "class RandAugment:\n",
    "    def __init__(self, ops, num_layers=2, choice_weights=None):\n",
    "        self.ops = ops\n",
    "        self.num_layers = num_layers\n",
    "        self.choice_weights = choice_weights\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # no replacement when using weighted choice\n",
    "        ops = np.random.choice(\n",
    "            self.ops, self.num_layers, replace=self.choice_weights is None, p=self.choice_weights)\n",
    "        for op in ops:\n",
    "            img = op(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        fs = self.__class__.__name__ + f'(n={self.num_layers}, ops='\n",
    "        for op in self.ops:\n",
    "            fs += f'\\n\\t{op}'\n",
    "        fs += ')'\n",
    "        return fs\n",
    "\n",
    "\n",
    "def rand_augment_transform(config_str, hparams):\n",
    "    \"\"\"\n",
    "    Create a RandAugment transform\n",
    "    :param config_str: String defining configuration of random augmentation. Consists of multiple sections separated by\n",
    "    dashes ('-'). The first section defines the specific variant of rand augment (currently only 'rand'). The remaining\n",
    "    sections, not order sepecific determine\n",
    "        'm' - integer magnitude of rand augment\n",
    "        'n' - integer num layers (number of transform ops selected per image)\n",
    "        'w' - integer probabiliy weight index (index of a set of weights to influence choice of op)\n",
    "        'mstd' -  float std deviation of magnitude noise applied, or uniform sampling if infinity (or > 100)\n",
    "        'mmax' - set upper bound for magnitude to something other than default of  _LEVEL_DENOM (10)\n",
    "        'inc' - integer (bool), use augmentations that increase in severity with magnitude (default: 0)\n",
    "    Ex 'rand-m9-n3-mstd0.5' results in RandAugment with magnitude 9, num_layers 3, magnitude_std 0.5\n",
    "    'rand-mstd1-w0' results in magnitude_std 1.0, weights 0, default magnitude of 10 and num_layers 2\n",
    "    :param hparams: Other hparams (kwargs) for the RandAugmentation scheme\n",
    "    :return: A PyTorch compatible Transform\n",
    "    \"\"\"\n",
    "    magnitude = _LEVEL_DENOM  # default to _LEVEL_DENOM for magnitude (currently 10)\n",
    "    num_layers = 2  # default to 2 ops per image\n",
    "    weight_idx = None  # default to no probability weights for op choice\n",
    "    transforms = _RAND_TRANSFORMS\n",
    "    config = config_str.split('-')\n",
    "    assert config[0] == 'rand'\n",
    "    config = config[1:]\n",
    "    for c in config:\n",
    "        cs = re.split(r'(\\d.*)', c)\n",
    "        if len(cs) < 2:\n",
    "            continue\n",
    "        key, val = cs[:2]\n",
    "        if key == 'mstd':\n",
    "            # noise param / randomization of magnitude values\n",
    "            mstd = float(val)\n",
    "            if mstd > 100:\n",
    "                # use uniform sampling in 0 to magnitude if mstd is > 100\n",
    "                mstd = float('inf')\n",
    "            hparams.setdefault('magnitude_std', mstd)\n",
    "        elif key == 'mmax':\n",
    "            # clip magnitude between [0, mmax] instead of default [0, _LEVEL_DENOM]\n",
    "            hparams.setdefault('magnitude_max', int(val))\n",
    "        elif key == 'inc':\n",
    "            if bool(val):\n",
    "                transforms = _RAND_INCREASING_TRANSFORMS\n",
    "        elif key == 'm':\n",
    "            magnitude = int(val)\n",
    "        elif key == 'n':\n",
    "            num_layers = int(val)\n",
    "        elif key == 'w':\n",
    "            weight_idx = int(val)\n",
    "        else:\n",
    "            assert False, 'Unknown RandAugment config section'\n",
    "    ra_ops = rand_augment_ops(magnitude=magnitude, hparams=hparams, transforms=transforms)\n",
    "    choice_weights = None if weight_idx is None else _select_rand_weights(weight_idx)\n",
    "    return RandAugment(ra_ops, num_layers, choice_weights=choice_weights)\n",
    "\n",
    "\n",
    "_AUGMIX_TRANSFORMS = [\n",
    "    'AutoContrast',\n",
    "    'ColorIncreasing',  # not in paper\n",
    "    'ContrastIncreasing',  # not in paper\n",
    "    'BrightnessIncreasing',  # not in paper\n",
    "    'SharpnessIncreasing',  # not in paper\n",
    "    'Equalize',\n",
    "    'Rotate',\n",
    "    'PosterizeIncreasing',\n",
    "    'SolarizeIncreasing',\n",
    "    'ShearX',\n",
    "    'ShearY',\n",
    "    'TranslateXRel',\n",
    "    'TranslateYRel',\n",
    "]\n",
    "\n",
    "\n",
    "def augmix_ops(magnitude=10, hparams=None, transforms=None):\n",
    "    hparams = hparams or _HPARAMS_DEFAULT\n",
    "    transforms = transforms or _AUGMIX_TRANSFORMS\n",
    "    return [AugmentOp(\n",
    "        name, prob=1.0, magnitude=magnitude, hparams=hparams) for name in transforms]\n",
    "\n",
    "\n",
    "class AugMixAugment:\n",
    "    \"\"\" AugMix Transform\n",
    "    Adapted and improved from impl here: https://github.com/google-research/augmix/blob/master/imagenet.py\n",
    "    From paper: 'AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty -\n",
    "    https://arxiv.org/abs/1912.02781\n",
    "    \"\"\"\n",
    "    def __init__(self, ops, alpha=1., width=3, depth=-1, blended=False):\n",
    "        self.ops = ops\n",
    "        self.alpha = alpha\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.blended = blended  # blended mode is faster but not well tested\n",
    "\n",
    "    def _calc_blended_weights(self, ws, m):\n",
    "        ws = ws * m\n",
    "        cump = 1.\n",
    "        rws = []\n",
    "        for w in ws[::-1]:\n",
    "            alpha = w / cump\n",
    "            cump *= (1 - alpha)\n",
    "            rws.append(alpha)\n",
    "        return np.array(rws[::-1], dtype=np.float32)\n",
    "\n",
    "    def _apply_blended(self, img, mixing_weights, m):\n",
    "        # This is my first crack and implementing a slightly faster mixed augmentation. Instead\n",
    "        # of accumulating the mix for each chain in a Numpy array and then blending with original,\n",
    "        # it recomputes the blending coefficients and applies one PIL image blend per chain.\n",
    "        # TODO the results appear in the right ballpark but they differ by more than rounding.\n",
    "        img_orig = img.copy()\n",
    "        ws = self._calc_blended_weights(mixing_weights, m)\n",
    "        for w in ws:\n",
    "            depth = self.depth if self.depth > 0 else np.random.randint(1, 4)\n",
    "            ops = np.random.choice(self.ops, depth, replace=True)\n",
    "            img_aug = img_orig  # no ops are in-place, deep copy not necessary\n",
    "            for op in ops:\n",
    "                img_aug = op(img_aug)\n",
    "            img = Image.blend(img, img_aug, w)\n",
    "        return img\n",
    "\n",
    "    def _apply_basic(self, img, mixing_weights, m):\n",
    "        # This is a literal adaptation of the paper/official implementation without normalizations and\n",
    "        # PIL <-> Numpy conversions between every op. It is still quite CPU compute heavy compared to the\n",
    "        # typical augmentation transforms, could use a GPU / Kornia implementation.\n",
    "        img_shape = img.size[0], img.size[1], len(img.getbands())\n",
    "        mixed = np.zeros(img_shape, dtype=np.float32)\n",
    "        for mw in mixing_weights:\n",
    "            depth = self.depth if self.depth > 0 else np.random.randint(1, 4)\n",
    "            ops = np.random.choice(self.ops, depth, replace=True)\n",
    "            img_aug = img  # no ops are in-place, deep copy not necessary\n",
    "            for op in ops:\n",
    "                img_aug = op(img_aug)\n",
    "            mixed += mw * np.asarray(img_aug, dtype=np.float32)\n",
    "        np.clip(mixed, 0, 255., out=mixed)\n",
    "        mixed = Image.fromarray(mixed.astype(np.uint8))\n",
    "        return Image.blend(img, mixed, m)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        mixing_weights = np.float32(np.random.dirichlet([self.alpha] * self.width))\n",
    "        m = np.float32(np.random.beta(self.alpha, self.alpha))\n",
    "        if self.blended:\n",
    "            mixed = self._apply_blended(img, mixing_weights, m)\n",
    "        else:\n",
    "            mixed = self._apply_basic(img, mixing_weights, m)\n",
    "        return mixed\n",
    "\n",
    "    def __repr__(self):\n",
    "        fs = self.__class__.__name__ + f'(alpha={self.alpha}, width={self.width}, depth={self.depth}, ops='\n",
    "        for op in self.ops:\n",
    "            fs += f'\\n\\t{op}'\n",
    "        fs += ')'\n",
    "        return fs\n",
    "\n",
    "\n",
    "def augment_and_mix_transform(config_str, hparams):\n",
    "    \"\"\" Create AugMix PyTorch transform\n",
    "    :param config_str: String defining configuration of random augmentation. Consists of multiple sections separated by\n",
    "    dashes ('-'). The first section defines the specific variant of rand augment (currently only 'rand'). The remaining\n",
    "    sections, not order sepecific determine\n",
    "        'm' - integer magnitude (severity) of augmentation mix (default: 3)\n",
    "        'w' - integer width of augmentation chain (default: 3)\n",
    "        'd' - integer depth of augmentation chain (-1 is random [1, 3], default: -1)\n",
    "        'b' - integer (bool), blend each branch of chain into end result without a final blend, less CPU (default: 0)\n",
    "        'mstd' -  float std deviation of magnitude noise applied (default: 0)\n",
    "    Ex 'augmix-m5-w4-d2' results in AugMix with severity 5, chain width 4, chain depth 2\n",
    "    :param hparams: Other hparams (kwargs) for the Augmentation transforms\n",
    "    :return: A PyTorch compatible Transform\n",
    "    \"\"\"\n",
    "    magnitude = 3\n",
    "    width = 3\n",
    "    depth = -1\n",
    "    alpha = 1.\n",
    "    blended = False\n",
    "    config = config_str.split('-')\n",
    "    assert config[0] == 'augmix'\n",
    "    config = config[1:]\n",
    "    for c in config:\n",
    "        cs = re.split(r'(\\d.*)', c)\n",
    "        if len(cs) < 2:\n",
    "            continue\n",
    "        key, val = cs[:2]\n",
    "        if key == 'mstd':\n",
    "            # noise param injected via hparams for now\n",
    "            hparams.setdefault('magnitude_std', float(val))\n",
    "        elif key == 'm':\n",
    "            magnitude = int(val)\n",
    "        elif key == 'w':\n",
    "            width = int(val)\n",
    "        elif key == 'd':\n",
    "            depth = int(val)\n",
    "        elif key == 'a':\n",
    "            alpha = float(val)\n",
    "        elif key == 'b':\n",
    "            blended = bool(val)\n",
    "        else:\n",
    "            assert False, 'Unknown AugMix config section'\n",
    "    hparams.setdefault('magnitude_std', float('inf'))  # default to uniform sampling (if not set via mstd arg)\n",
    "    ops = augmix_ops(magnitude=magnitude, hparams=hparams)\n",
    "    return AugMixAugment(ops, alpha=alpha, width=width, depth=depth, blended=blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9410071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T17:28:42.505031Z",
     "iopub.status.busy": "2022-03-22T17:28:42.503472Z",
     "iopub.status.idle": "2022-03-22T17:28:42.505654Z",
     "shell.execute_reply": "2022-03-22T17:28:42.506049Z",
     "shell.execute_reply.started": "2022-03-22T16:08:20.013178Z"
    },
    "papermill": {
     "duration": 0.019648,
     "end_time": "2022-03-22T17:28:42.506169",
     "exception": false,
     "start_time": "2022-03-22T17:28:42.486521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!cp -r ../input/cifar-100-128 ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eefad62f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T17:28:42.539638Z",
     "iopub.status.busy": "2022-03-22T17:28:42.539020Z",
     "iopub.status.idle": "2022-03-22T17:28:42.541959Z",
     "shell.execute_reply": "2022-03-22T17:28:42.542391Z",
     "shell.execute_reply.started": "2022-03-22T16:15:36.448543Z"
    },
    "papermill": {
     "duration": 0.023101,
     "end_time": "2022-03-22T17:28:42.542509",
     "exception": false,
     "start_time": "2022-03-22T17:28:42.519408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import os\\nimport shutil\\ntraindir = './cifar-100-128/train'\\ntrain_classes = sorted(os.listdir(traindir))\\n\\nfor label in train_classes:\\n    path = os.path.join('./cifar-100-128/val',label)\\n    os.makedirs(path)\\n\\ndef move_files_to_folder(list_of_files, destination_folder):\\n    for f in list_of_files:\\n        try:\\n            shutil.move(f, destination_folder)\\n        except:\\n            print(f)\\n            assert False\\n\\nfor label in train_classes:\\n    path_train = os.path.join('./cifar-100-128/train',label)\\n    images_label_list = os.listdir(path_train)\\n    val_images_label = images_label_list[:25]\\n    imgs_to_move = []\\n    for img in val_images_label:\\n        imgs_to_move.append(os.path.join(path_train,img))\\n        \\n    path_val = os.path.join('./cifar-100-128/val',label)\\n    move_files_to_folder(imgs_to_move,path_val) \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import os\n",
    "import shutil\n",
    "traindir = './cifar-100-128/train'\n",
    "train_classes = sorted(os.listdir(traindir))\n",
    "\n",
    "for label in train_classes:\n",
    "    path = os.path.join('./cifar-100-128/val',label)\n",
    "    os.makedirs(path)\n",
    "\n",
    "def move_files_to_folder(list_of_files, destination_folder):\n",
    "    for f in list_of_files:\n",
    "        try:\n",
    "            shutil.move(f, destination_folder)\n",
    "        except:\n",
    "            print(f)\n",
    "            assert False\n",
    "\n",
    "for label in train_classes:\n",
    "    path_train = os.path.join('./cifar-100-128/train',label)\n",
    "    images_label_list = os.listdir(path_train)\n",
    "    val_images_label = images_label_list[:25]\n",
    "    imgs_to_move = []\n",
    "    for img in val_images_label:\n",
    "        imgs_to_move.append(os.path.join(path_train,img))\n",
    "        \n",
    "    path_val = os.path.join('./cifar-100-128/val',label)\n",
    "    move_files_to_folder(imgs_to_move,path_val) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3815668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T17:28:42.593854Z",
     "iopub.status.busy": "2022-03-22T17:28:42.588424Z",
     "iopub.status.idle": "2022-03-22T17:28:42.642417Z",
     "shell.execute_reply": "2022-03-22T17:28:42.642808Z",
     "shell.execute_reply.started": "2022-03-22T17:23:59.339634Z"
    },
    "papermill": {
     "duration": 0.086482,
     "end_time": "2022-03-22T17:28:42.642934",
     "exception": false,
     "start_time": "2022-03-22T17:28:42.556452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "class rSoftMax(nn.Module):\n",
    "    def __init__(self, radix, cardinality):\n",
    "        super().__init__()\n",
    "        self.radix = radix\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.size(0)\n",
    "        if self.radix > 1:\n",
    "            x = x.view(batch, self.cardinality, self.radix, -1).transpose(1, 2)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            x = x.reshape(batch, -1)\n",
    "        else:\n",
    "            x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "def channel_shuffle(x, groups):\n",
    "    batchsize, num_channels, height, width = x.data.size()\n",
    "\n",
    "    channels_per_group = num_channels // groups\n",
    "    \n",
    "    # reshape\n",
    "    x = x.view(batchsize, groups, \n",
    "        channels_per_group, height, width)\n",
    "\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "\n",
    "    # flatten\n",
    "    x = x.view(batchsize, -1, height, width)\n",
    "\n",
    "    return x\n",
    "\n",
    "class SplitAttn(nn.Module):\n",
    "    def __init__(self, c1, c2=None, kernel_size=3, stride=1, padding=None,\n",
    "                 dilation=1, groups=1, bias=False, radix=2, rd_ratio=0.25, rd_channels=None, rd_divisor=8,\n",
    "                 act_layer=nn.SiLU, norm_layer=None, drop_block=None, **kwargs):\n",
    "        super(SplitAttn, self).__init__()\n",
    "        c2 = c2 or c1\n",
    "        self.radix = radix\n",
    "        self.drop_block = drop_block\n",
    "        mid_chs = c2 * radix\n",
    "        if rd_channels is None:\n",
    "            attn_chs = _make_divisible(c1 * radix * rd_ratio, min_value=32, divisor=rd_divisor)\n",
    "        else:\n",
    "            attn_chs = rd_channels * radix\n",
    "\n",
    "        padding = kernel_size // 2 if padding is None else padding\n",
    "        self.conv = nn.Conv2d(\n",
    "            c1, mid_chs, kernel_size, stride, padding, dilation,\n",
    "            groups=groups * radix, bias=bias, **kwargs)\n",
    "        self.bn0 = norm_layer(mid_chs) if norm_layer else nn.Identity()\n",
    "        self.act0 = act_layer()\n",
    "        self.fc1 = nn.Conv2d(c2, attn_chs, 1, groups=groups)\n",
    "        self.bn1 = norm_layer(attn_chs) if norm_layer else nn.Identity()\n",
    "        self.act1 = act_layer()\n",
    "        self.fc2 = nn.Conv2d(attn_chs, mid_chs, 1, groups=groups)\n",
    "        self.rsoftmax = rSoftMax(radix, groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn0(x)\n",
    "        if self.drop_block is not None:\n",
    "            x = self.drop_block(x)\n",
    "        x = self.act0(x)\n",
    "\n",
    "        B, RC, H, W = x.shape\n",
    "        if self.radix > 1:\n",
    "            x = x.reshape((B, self.radix, RC // self.radix, H, W))\n",
    "            x_gap = x.sum(dim=1)\n",
    "        else:\n",
    "            x_gap = x\n",
    "        x_gap = x_gap.mean((2, 3), keepdim=True)\n",
    "        x_gap = self.fc1(x_gap)\n",
    "        x_gap = self.bn1(x_gap)\n",
    "        x_gap = self.act1(x_gap)\n",
    "        x_attn = self.fc2(x_gap)\n",
    "\n",
    "        x_attn = self.rsoftmax(x_attn).view(B, -1, 1, 1)\n",
    "        if self.radix > 1:\n",
    "            out = (x * x_attn.reshape((B, self.radix, RC // self.radix, 1, 1))).sum(dim=1)\n",
    "        else:\n",
    "            out = x * x_attn\n",
    "        output = out.contiguous()\n",
    "        return output\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, inp, oup, reduction=4):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(oup, _make_divisible(inp // reduction, 8)),\n",
    "                Mish(),\n",
    "                nn.Linear(_make_divisible(inp // reduction, 8), oup),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first. \n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_first\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError \n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x\n",
    "\n",
    "class Mish_func(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.tanh(F.softplus(i))\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_tensors[0]\n",
    "  \n",
    "        v = 1. + i.exp()\n",
    "        h = v.log() \n",
    "        grad_gh = 1./h.cosh().pow_(2) \n",
    "\n",
    "        # Note that grad_hv * grad_vx = sigmoid(x)\n",
    "        #grad_hv = 1./v  \n",
    "        #grad_vx = i.exp()\n",
    "        grad_hx = i.sigmoid()\n",
    "\n",
    "        grad_gx = grad_gh *  grad_hx #grad_hv * grad_vx \n",
    "        \n",
    "        grad_f =  torch.tanh(F.softplus(i)) + i * grad_gx \n",
    "        \n",
    "        return grad_output * grad_f \n",
    "\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    def forward(self, input_tensor):\n",
    "        return Mish_func.apply(input_tensor)\n",
    "\n",
    "class MixConv2d(nn.Module):\n",
    "    # Mixed Depth-wise Conv https://arxiv.org/abs/1907.09595\n",
    "    def __init__(self, c1, c2, k=(1, 3), s=1, equal_ch=True):  # ch_in, ch_out, kernel, stride, ch_strategy\n",
    "        super().__init__()\n",
    "        n = len(k)  # number of convolutions\n",
    "        if equal_ch:  # equal c_ per group\n",
    "            i = torch.linspace(0, n - 1E-6, c2).floor()  # c2 indices\n",
    "            c_ = [(i == g).sum() for g in range(n)]  # intermediate channels\n",
    "        else:  # equal weight.numel() per group\n",
    "            b = [c2] + [0] * n\n",
    "            a = np.eye(n + 1, n, k=-1)\n",
    "            a -= np.roll(a, 1, axis=1)\n",
    "            a *= np.array(k) ** 2\n",
    "            a[0] = 1\n",
    "            c_ = np.linalg.lstsq(a, b, rcond=None)[0].round()  # solve for equal weight indices, ax = b\n",
    "\n",
    "        self.m = nn.ModuleList(\n",
    "            [nn.Conv2d(c1, int(c_), k, s, k // 2, groups=math.gcd(c1, int(c_)), bias=False) for k, c_ in zip(k, c_)])\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act = Mish()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(torch.cat([m(x) for m in self.m], 1)))\n",
    "\n",
    "class MSBlock(nn.Module):\n",
    "    def __init__(self, c1, c2, stride, use_se, radix=2, expand_ratio=1):\n",
    "        super(MSBlock, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(c1 * expand_ratio)\n",
    "        self.identity = stride == 1 and c1 == c2\n",
    "        self.stride = stride\n",
    "        if not self.identity:\n",
    "            if stride > 1:\n",
    "                self.down = nn.Sequential(nn.MaxPool2d(3,2,1),\n",
    "                                          nn.Conv2d(c1,c2,1,1,0,bias=False))\n",
    "            else:\n",
    "                self.down = nn.Conv2d(c1,c2,1,1,0,bias=False)\n",
    "            \n",
    "        \n",
    "        if use_se:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv2d(c1,hidden_dim,1,1,0,bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                Mish(),\n",
    "                #mixed conv\n",
    "                MixConv2d(hidden_dim,hidden_dim,k=(3,5),s=stride,equal_ch=True),\n",
    "                #se\n",
    "                SELayer(c1, hidden_dim),\n",
    "                #pointwise\n",
    "                nn.Conv2d(hidden_dim,c2,1,1,0,bias=False),\n",
    "                nn.BatchNorm2d(c2),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                #mixconv\n",
    "                MixConv2d(c1,hidden_dim,k=(3,5,7,9),s=1,equal_ch=True),\n",
    "                #split attention - radix = 2 - SK-Unit, radix = 1 - SE-Layer\n",
    "                SplitAttn(c1=hidden_dim,c2=c2,stride=stride,groups=1,radix=radix,\n",
    "                          rd_ratio=0.25, act_layer=Mish, norm_layer=nn.BatchNorm2d),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            out = x + self.conv(x)\n",
    "        else:\n",
    "            out = self.down(x) + self.conv(x)\n",
    "        return channel_shuffle(out,2)\n",
    "\n",
    "def conv_3x3_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        Mish()\n",
    "    )\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        Mish()\n",
    "    )\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "class MESNeSt(nn.Module):\n",
    "    def __init__(self, cfgs, num_classes=1000, width_mult=1.):\n",
    "        super(MESNeSt, self).__init__()\n",
    "        self.cfgs = cfgs\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(24 * width_mult, 8)\n",
    "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        block = MSBlock\n",
    "        for t, c, n, s, use_se, radix in self.cfgs:\n",
    "            output_channel = _make_divisible(c * width_mult, 8)\n",
    "            for i in range(n):\n",
    "                layers.append(block(input_channel, output_channel, s if i == 0 else 1, use_se, radix, t))\n",
    "                input_channel = output_channel\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        # building last several layers\n",
    "        output_channel = _make_divisible(1792 * width_mult, 8) if width_mult > 1.0 else 1792\n",
    "        self.conv = conv_1x1_bn(input_channel, output_channel)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(output_channel, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.001)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def mesnest_s(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a Mixconv-Efficient-Shuffle-NeSt-S model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # t, c, n, s, SE, radix\n",
    "        [1,  24,  2, 1, 0, 2],\n",
    "        [4,  48,  4, 2, 0, 2],\n",
    "        [4,  64,  4, 2, 0, 2],\n",
    "        [4, 128,  6, 2, 1, 1],\n",
    "        [6, 160,  9, 1, 1, 1],\n",
    "        [6, 256, 15, 2, 1, 1],\n",
    "    ]\n",
    "    return MESNeSt(cfgs, **kwargs)\n",
    "\n",
    "\n",
    "def mesnest_m(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a Mixconv-Efficient-Shuffle-NeSt-M model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # t, c, n, s, SE, radix\n",
    "        [1,  24,  3, 1, 0, 2],\n",
    "        [4,  48,  5, 2, 0, 2],\n",
    "        [4,  80,  5, 2, 0, 2],\n",
    "        [4, 160,  7, 2, 1, 1],\n",
    "        [6, 176, 14, 1, 1, 1],\n",
    "        [6, 304, 18, 2, 1, 1],\n",
    "        [6, 512,  5, 1, 1, 1],\n",
    "    ]\n",
    "    return MESNeSt(cfgs, **kwargs)\n",
    "\n",
    "\n",
    "def mesnest_l(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a Mixconv-Efficient-Shuffle-NeSt-L model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # t, c, n, s, SE, radix\n",
    "        [1,  32,  4, 1, 0, 2],\n",
    "        [4,  64,  7, 2, 0, 2],\n",
    "        [4,  96,  7, 2, 0, 2],\n",
    "        [4, 192, 10, 2, 1, 1],\n",
    "        [6, 224, 19, 1, 1, 1],\n",
    "        [6, 384, 25, 2, 1, 1],\n",
    "        [6, 640,  7, 1, 1, 1],\n",
    "    ]\n",
    "    return MESNeSt(cfgs, **kwargs)\n",
    "\n",
    "\n",
    "def mesnest_xl(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a Mixconv-Efficient-Shuffle-NeSt-XL model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # t, c, n, s, SE, radix\n",
    "        [1,  32,  4, 1, 0, 2],\n",
    "        [4,  64,  8, 2, 0, 2],\n",
    "        [4,  96,  8, 2, 0, 2],\n",
    "        [4, 192, 16, 2, 1, 1],\n",
    "        [6, 256, 24, 1, 1, 1],\n",
    "        [6, 512, 32, 2, 1, 1],\n",
    "        [6, 640,  8, 1, 1, 1],\n",
    "    ]\n",
    "    return MESNeSt(cfgs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095555a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T17:28:42.680100Z",
     "iopub.status.busy": "2022-03-22T17:28:42.679546Z",
     "iopub.status.idle": "2022-03-22T17:28:42.730125Z",
     "shell.execute_reply": "2022-03-22T17:28:42.729707Z",
     "shell.execute_reply.started": "2022-03-22T17:23:59.421742Z"
    },
    "papermill": {
     "duration": 0.072974,
     "end_time": "2022-03-22T17:28:42.730253",
     "exception": false,
     "start_time": "2022-03-22T17:28:42.657279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    traindir = '../input/cifar-train-val-test/cifar10-train-val-test/train'\n",
    "    valdir = '../input/cifar-train-val-test/cifar10-train-val-test/val'\n",
    "    testdir = '../input/cifar-train-val-test/cifar10-train-val-test/test'\n",
    "    save_dir = './model_dir'\n",
    "    cifar_100_traindir = '../input/cifar-100-128/train'\n",
    "    cifar_100_valdir = './cifar-100-128/val'\n",
    "    cifar_100_testdir = '../input/cifar-100-128/test'\n",
    "    seed = 42\n",
    "    img_size = 128\n",
    "    clr = '10,13.68,0.95,0.85'\n",
    "    use_clr = tuple(map(float, clr.split(',')))\n",
    "    scheduler = 'CosineAnnealingLR'\n",
    "    cycle_len = 15\n",
    "    T_max = 10\n",
    "    lr = 1e-4\n",
    "    min_lr = 1e-6\n",
    "    batch_size = 8\n",
    "    weight_decay = 1e-6\n",
    "    num_epochs = 3\n",
    "    num_classes = 100\n",
    "    n_accumulate = 4\n",
    "    temperature = 0.1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d534a113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T17:28:42.789535Z",
     "iopub.status.busy": "2022-03-22T17:28:42.788810Z",
     "iopub.status.idle": "2022-03-22T17:28:49.342390Z",
     "shell.execute_reply": "2022-03-22T17:28:49.341878Z",
     "shell.execute_reply.started": "2022-03-22T17:23:59.481341Z"
    },
    "papermill": {
     "duration": 6.598465,
     "end_time": "2022-03-22T17:28:49.342528",
     "exception": false,
     "start_time": "2022-03-22T17:28:42.744063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.4914 , 0.48216, 0.44653], std=[0.24703, 0.24349, 0.26159])\n",
    "        \n",
    "train_dataset = datasets.ImageFolder(\n",
    "        CFG.cifar_100_traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(512,interpolation=3),\n",
    "            transforms.CenterCrop(512),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(.2,.2,.2),\n",
    "            auto_augment_transform('original-mstd0.5',{}),\n",
    "            #rand_augment_transform('rand-m9-n3-mstd0.5',{}),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=CFG.batch_size, shuffle=True,\n",
    "        num_workers=2, pin_memory=True, sampler=None)\n",
    "\n",
    "#val_loader = torch.utils.data.DataLoader(\n",
    "#        datasets.ImageFolder(CFG.valdir, transforms.Compose([\n",
    "#            transforms.Resize(512, interpolation=3),\n",
    "#            transforms.ToTensor(),\n",
    "#            normalize,\n",
    "#        ])),\n",
    "#        batch_size=CFG.batch_size, shuffle=False, #Always False\n",
    "#        num_workers=2, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(CFG.cifar_100_testdir, transforms.Compose([\n",
    "            transforms.Resize(512, interpolation=3),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=1, shuffle=False, #Always False\n",
    "        num_workers=2, pin_memory=True)\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "    \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "    \n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, scheduler, epoch, step):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(tqdm(train_loader)):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "    \n",
    "        images = images.to(CFG.device)\n",
    "        target = target.to(CFG.device)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (step + 1) % CFG.n_accumulate == 0:\n",
    "            scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        \n",
    "    progress.display(len(train_loader))\n",
    "    return top1.avg, losses.avg\n",
    "    \n",
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            images = images.to(CFG.device)\n",
    "            target = target.to(CFG.device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            #if i % args.print_freq == 0:\n",
    "                #progress.display(i)\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f} Val-Loss {losses.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5, losses=losses))\n",
    "    return top1.avg , losses.avg\n",
    "        \n",
    "def train_model(model,train_loader,criterion,optimizer, scheduler, num_epochs):\n",
    "    best_loss = np.Inf\n",
    "    best_acc = 0\n",
    "\n",
    "    for step, epoch in enumerate(range(1,num_epochs+1)):\n",
    "        top1,loss = train(train_loader,model,criterion,optimizer,scheduler,epoch,step)\n",
    "        #val_acc_top1, val_loss = validate(val_loader,model,criterion)\n",
    "        PATH = f'mesnest_m_epoch_{epoch}_loss_{loss}_acc_{top1}.pt'\n",
    "        #if (val_acc_top1 > best_acc) and (val_loss < best_loss):\n",
    "            #best_loss = val_loss\n",
    "            #best_acc = val_acc_top1\n",
    "            #PATH = f'mesnest_m_epoch_{epoch}_val_loss_{best_loss}_val_acc_{best_acc}.pt'\n",
    "        \n",
    "        torch.save(model.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b898da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T17:28:49.377479Z",
     "iopub.status.busy": "2022-03-22T17:28:49.376870Z",
     "iopub.status.idle": "2022-03-22T17:28:56.608393Z",
     "shell.execute_reply": "2022-03-22T17:28:56.607950Z",
     "shell.execute_reply.started": "2022-03-22T17:24:14.393665Z"
    },
    "papermill": {
     "duration": 7.251183,
     "end_time": "2022-03-22T17:28:56.608529",
     "exception": false,
     "start_time": "2022-03-22T17:28:49.357346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mesnest_m(num_classes=100)\n",
    "model = model.to(CFG.device)\n",
    "model.load_state_dict(torch.load('../input/mesnest-cifar-weights/cifar_100_mesnest_m_epoch_45_acc_62.59_loss_1.38.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f36df81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T17:28:56.647450Z",
     "iopub.status.busy": "2022-03-22T17:28:56.646908Z",
     "iopub.status.idle": "2022-03-22T17:28:56.649643Z",
     "shell.execute_reply": "2022-03-22T17:28:56.650000Z",
     "shell.execute_reply.started": "2022-03-22T17:24:24.011416Z"
    },
    "papermill": {
     "duration": 0.026924,
     "end_time": "2022-03-22T17:28:56.650127",
     "exception": false,
     "start_time": "2022-03-22T17:28:56.623203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a57e204a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T17:28:56.686726Z",
     "iopub.status.busy": "2022-03-22T17:28:56.685912Z",
     "iopub.status.idle": "2022-03-23T02:46:06.300756Z",
     "shell.execute_reply": "2022-03-23T02:46:06.295785Z"
    },
    "papermill": {
     "duration": 33429.636515,
     "end_time": "2022-03-23T02:46:06.301012",
     "exception": false,
     "start_time": "2022-03-22T17:28:56.664497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6244/6244 [3:05:52<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6244/6244]\tTime  8.691 ( 1.786)\tData  0.001 ( 0.002)\tLoss 5.5303e-01 (1.9459e+00)\tAcc@1  85.71 ( 48.55)\tAcc@5 100.00 ( 78.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6244/6244 [3:05:34<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][6244/6244]\tTime  1.611 ( 1.783)\tData  0.001 ( 0.002)\tLoss 1.1719e+00 (1.4102e+00)\tAcc@1  57.14 ( 60.64)\tAcc@5 100.00 ( 87.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6244/6244 [3:05:37<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][6244/6244]\tTime  1.608 ( 1.784)\tData  0.002 ( 0.002)\tLoss 1.8294e+00 (1.2262e+00)\tAcc@1  57.14 ( 65.20)\tAcc@5  57.14 ( 89.75)\n"
     ]
    }
   ],
   "source": [
    "train_model(model,train_loader,criterion,optimizer,scheduler,CFG.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c58f0b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T02:46:18.160478Z",
     "iopub.status.busy": "2022-03-23T02:46:18.158895Z",
     "iopub.status.idle": "2022-03-23T02:46:18.161038Z",
     "shell.execute_reply": "2022-03-23T02:46:18.161460Z",
     "shell.execute_reply.started": "2022-03-22T14:21:31.585443Z"
    },
    "papermill": {
     "duration": 5.815167,
     "end_time": "2022-03-23T02:46:18.161612",
     "exception": false,
     "start_time": "2022-03-23T02:46:12.346445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('./mesnest_s_epoch_1_loss_0.19724411217171792_acc_94.71281433105469.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17715f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T02:46:29.818924Z",
     "iopub.status.busy": "2022-03-23T02:46:29.818106Z",
     "iopub.status.idle": "2022-03-23T02:57:04.247086Z",
     "shell.execute_reply": "2022-03-23T02:57:04.247779Z",
     "shell.execute_reply.started": "2022-03-22T14:21:34.935683Z"
    },
    "papermill": {
     "duration": 640.163649,
     "end_time": "2022-03-23T02:57:04.247934",
     "exception": false,
     "start_time": "2022-03-23T02:46:24.084285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 Test Accuracy - 69.56999969482422\n",
      "Top 5 Test Accuracy - 90.47999572753906\n"
     ]
    }
   ],
   "source": [
    "def testing(test_loader,model):\n",
    "    model.eval()\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    \n",
    "    for i,(images,labels) in enumerate(test_loader):\n",
    "        images = images.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        acc1, acc5 = accuracy(outputs, labels, topk=(1, 5))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        \n",
    "    print(f'Top 1 Test Accuracy - {top1.avg}')\n",
    "    print(f'Top 5 Test Accuracy - {top5.avg}')\n",
    "    \n",
    "testing(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48857154",
   "metadata": {
    "papermill": {
     "duration": 6.012865,
     "end_time": "2022-03-23T02:57:16.065790",
     "exception": false,
     "start_time": "2022-03-23T02:57:10.052925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34143.581759,
   "end_time": "2022-03-23T02:57:23.836149",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-22T17:28:20.254390",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
